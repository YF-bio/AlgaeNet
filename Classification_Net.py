# 数据集引用import torchimport timefrom torch import nnimport torch.nn.functional as Fimport torch.optim as optimimport osimport Dataset_Make# 数据集加载Train_Dataloader, Test_Dataloader = Dataset_Make.Dataset_Maker(Dataset_Make.Root_Dir + 'Dataset/', 32)# 数据集类别定义classes = ('Chlorella', 'Chrysophyceae')# 训练网络搭建class Net(nn.Module):    def __init__(self):        super(Net, self).__init__()        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)  # 输入 3 通道， 输出 64 通道， 卷积核 3 * 3， padding = 1        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)  # 输入 64 通道， 输出 64 通道， 卷积核 3 * 3， padding = 1        self.pool1 = nn.MaxPool2d(2, 2)  # 以 2 * 2 为窗口，步长为 2 ， 池化        self.bn1 = nn.BatchNorm2d(64)  # 神经网络加速， 输出 Chanel = 64        self.relu1 = nn.ReLU()  # 激活函数 ReLU        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)  # 输入 64 通道， 输出 128 通道， 卷积核 3 * 3， padding = 1        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)  # 输入 128 通道， 输出 128 通道， 卷积核 3 * 3， padding = 1        self.pool2 = nn.MaxPool2d(2, 2, padding=1)  # 以 2 * 2 为窗口，步长为 2 ，padding = 1 池化        self.bn2 = nn.BatchNorm2d(128)  # 神经网络加速， 输出 Chanel = 128        self.relu2 = nn.ReLU()        self.conv5 = nn.Conv2d(128, 128, 3, padding=1)        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)        self.conv7 = nn.Conv2d(128, 128, 1, padding=1)        self.pool3 = nn.MaxPool2d(2, 2, padding=1)        self.bn3 = nn.BatchNorm2d(128)        self.relu3 = nn.ReLU()        self.conv8 = nn.Conv2d(128, 256, 3, padding=1)        self.conv9 = nn.Conv2d(256, 256, 3, padding=1)        self.conv10 = nn.Conv2d(256, 256, 1, padding=1)        self.pool4 = nn.MaxPool2d(2, 2, padding=1)        self.bn4 = nn.BatchNorm2d(256)        self.relu4 = nn.ReLU()        self.conv11 = nn.Conv2d(256, 512, 3, padding=1)        self.conv12 = nn.Conv2d(512, 512, 3, padding=1)        self.conv13 = nn.Conv2d(512, 512, 1, padding=1)        self.pool5 = nn.MaxPool2d(2, 2, padding=1)        self.bn5 = nn.BatchNorm2d(512)        self.relu5 = nn.ReLU()        self.fc14 = nn.Linear(512 * 4 * 4, 1024)        self.drop1 = nn.Dropout2d()        self.fc15 = nn.Linear(1024, 1024)        self.drop2 = nn.Dropout2d()        self.fc16 = nn.Linear(1024, 2)    def forward(self, x):        x = self.conv1(x)        x = self.conv2(x)        x = self.pool1(x)        x = self.bn1(x)        x = self.relu1(x)        x = self.conv3(x)        x = self.conv4(x)        x = self.pool2(x)        x = self.bn2(x)        x = self.relu2(x)        x = self.conv5(x)        x = self.conv6(x)        x = self.conv7(x)        x = self.pool3(x)        x = self.bn3(x)        x = self.relu3(x)        x = self.conv8(x)        x = self.conv9(x)        x = self.conv10(x)        x = self.pool4(x)        x = self.bn4(x)        x = self.relu4(x)        x = self.conv11(x)        x = self.conv12(x)        x = self.conv13(x)        x = self.pool5(x)        x = self.bn5(x)        x = self.relu5(x)        # print(" x shape ",x.size())        x = x.view(-1, 512 * 4 * 4)        x = F.relu(self.fc14(x))        x = self.drop1(x)        x = F.relu(self.fc15(x))        x = self.drop2(x)        x = self.fc16(x)        return x    def train_sgd(self, device):        optimizer = optim.Adam(self.parameters(), lr=0.0001)        path = 'weights.tar'        initepoch = 0        if os.path.exists(path) is not True:            loss = nn.CrossEntropyLoss()            # optimizer = optim.SGD(self.parameters(),lr=0.01)        else:            checkpoint = torch.load(path)            self.load_state_dict(checkpoint['model_state_dict'])            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])            initepoch = checkpoint['epoch']            loss = checkpoint['loss']        for epoch in range(initepoch, 100):  # loop over the dataset multiple times            timestart = time.time()            running_loss = 0.0            total = 0            correct = 0            for i, data in enumerate(Train_Dataloader, 0):                # get the inputs                inputs, labels = data                inputs, labels = inputs.to(device), labels.to(device)                # zero the parameter gradients                optimizer.zero_grad()                # forward + backward + optimize                outputs = self(inputs)                l = loss(outputs, labels)                l.backward()                optimizer.step()                # print statistics                running_loss += l.item()                # print("i ",i)                if i % 20 == 19:  # print every 500 mini-batches                    print('[%d, %5d] loss: %.4f' %                          (epoch, i, running_loss / 20))                    running_loss = 0.0                    _, predicted = torch.max(outputs.data, 1)                    total += labels.size(0)                    correct += (predicted == labels).sum().item()                    print('Accuracy of the network on the %d train images: %.3f %%' % (total,                                                                                       100.0 * correct / total))                    total = 0                    correct = 0                    torch.save({'epoch': epoch,                                'model_state_dict': net.state_dict(),                                'optimizer_state_dict': optimizer.state_dict(),                                'loss': loss                                }, path)            print('epoch %d cost %3f sec' % (epoch, time.time() - timestart))        print('Finished Training')    def test(self, device):        correct = 0        total = 0        with torch.no_grad():            for data in Test_Dataloader:                images, labels = data                images, labels = images.to(device), labels.to(device)                outputs = self(images)                _, predicted = torch.max(outputs.data, 1)                total += labels.size(0)                correct += (predicted == labels).sum().item()        print('Accuracy of the network on test images: %.3f %%' % (                100.0 * correct / total))# 网络生成net = Net()# 选择运行设备device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")# 将网络转移至设备net = net.to(device)# 开始训练net.train_sgd(device)# 进行测试net.test(device)